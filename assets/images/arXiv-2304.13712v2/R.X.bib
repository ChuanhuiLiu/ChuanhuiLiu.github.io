@inproceedings{lee2022deduplicating,
  title={Deduplicating Training Data Makes Language Models Better},
  author={Lee, Katherine and Ippolito, Daphne and Nystrom, Andrew and Zhang, Chiyuan and Eck, Douglas and Callison-Burch, Chris and Carlini, Nicholas},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={8424--8445},
  year={2022}
}



@inproceedings{alajrami2022does,
  title={How does the pre-training objective affect what large language models learn about linguistic properties?},
  author={Alajrami, Ahmed and Aletras, Nikolaos},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={131--147},
  year={2022}
}

@article{hu2022text,
  title={Text style transfer: A review and experimental evaluation},
  author={Hu, Zhiqiang and Lee, Roy Ka-Wei and Aggarwal, Charu C and Zhang, Aston},
  journal={ACM SIGKDD Explorations Newsletter},
  volume={24},
  number={1},
  pages={14--45},
  year={2022},
  publisher={ACM New York, NY, USA}
}



@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}




@inproceedings{lee2022meta,
  title={Meta Learning for Natural Language Processing: A Survey},
  author={Lee, Hung-Yi and Li, Shang-Wen and Vu, Thang},
  booktitle={Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={666--684},
  year={2022}
}

@article{ruder2019transfer,
  title={Transfer Learning in Natural Language Processing Tutorial},
  author={Ruder, Sebastian and Peters, Matthew and Swayamdipta, Swabha and Wolf, Thomas},
  journal={NAACL HTL 2019},
  pages={15},
  year={2019}
}



@article{zhou2022domain,
  title={Domain generalization: A survey},
  author={Zhou, Kaiyang and Liu, Ziwei and Qiao, Yu and Xiang, Tao and Loy, Chen Change},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2022},
  publisher={IEEE}
}

@article{du2022shortcut,
  title={Shortcut learning of large language models in natural language understanding: A survey},
  author={Du, Mengnan and He, Fengxiang and Zou, Na and Tao, Dacheng and Hu, Xia},
  journal={arXiv preprint arXiv:2208.11857},
  year={2022}
}

@article{qiu2022adversarial,
  title={Adversarial attack and defense technologies in natural language processing: A survey},
  author={Qiu, Shilin and Liu, Qihe and Zhou, Shijie and Huang, Wen},
  journal={Neurocomputing},
  volume={492},
  pages={278--307},
  year={2022},
  publisher={Elsevier}
}



@article{wang2023robustness,
  title={On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective},
  author={Wang, Jindong and Hu, Xixu and Hou, Wenxin and Chen, Hao and Zheng, Runkai and Wang, Yidong and Yang, Linyi and Huang, Haojun and Ye, Wei and Geng, Xiubo and others},
  journal={arXiv preprint arXiv:2302.12095},
  year={2023}
}

@article{tchango2022ddxplus,
  title={DDXPlus: A New Dataset For Automatic Medical Diagnosis},
  author={Tchango, Arsene Fansi and Goel, Rishab and Wen, Zhi and Martel, Julien and Ghosn, Joumana},
  journal={Proceedings of the Neural Information Processing Systems-Track on Datasets and Benchmarks},
  volume={2},
  year={2022}
}

@inproceedings{webson2022prompt,
  title={Do Prompt-Based Models Really Understand the Meaning of Their Prompts?},
  author={Webson, Albert and Pavlick, Ellie},
  booktitle={Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={2300--2344},
  year={2022}
}




@inproceedings{lai2021machine,
  title={Why Machine Reading Comprehension Models Learn Shortcuts?},
  author={Lai, Yuxuan and Zhang, Chen and Feng, Yansong and Huang, Quzhe and Zhao, Dongyan},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={989--1002},
  year={2021}
}



@article{geirhos2020shortcut,
  title={Shortcut learning in deep neural networks},
  author={Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A},
  journal={Nature Machine Intelligence},
  volume={2},
  number={11},
  pages={665--673},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{zhong2023can,
  title={Can chatgpt understand too? a comparative study on chatgpt and fine-tuned bert},
  author={Zhong, Qihuang and Ding, Liang and Liu, Juhua and Du, Bo and Tao, Dacheng},
  journal={arXiv preprint arXiv:2302.10198},
  year={2023}
}

@inproceedings{yin2019benchmarking,
  title={Benchmarking Zero-shot Text Classification: Datasets, Evaluation and Entailment Approach},
  author={Yin, Wenpeng and Hay, Jamaal and Roth, Dan},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={3914--3923},
  year={2019}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@inproceedings{niven2019probing,
  title={Probing Neural Network Comprehension of Natural Language Arguments},
  author={Niven, Timothy and Kao, Hung-Yu},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={4658--4664},
  year={2019}
}

@inproceedings{tang2021mitigating,
  title={Mitigating gender bias in captioning systems},
  author={Tang, Ruixiang and Du, Mengnan and Li, Yuening and Liu, Zirui and Zou, Na and Hu, Xia},
  booktitle={Proceedings of the Web Conference 2021},
  pages={633--645},
  year={2021}
}

@article{tang2023science,
  title={The Science of Detecting LLM-Generated Texts},
  author={Tang, Ruixiang and Chuang, Yu-Neng and Hu, Xia},
  journal={arXiv preprint arXiv:2303.07205},
  year={2023}
}

@article{yuan2023llm,
  title={LLM for Patient-Trial Matching: Privacy-Aware Data Augmentation Towards Better Performance and Generalizability},
  author={Yuan, Jiayi and Tang, Ruixiang and Jiang, Xiaoqian and Hu, Xia},
  journal={arXiv preprint arXiv:2303.16756},
  year={2023}
}

@inproceedings{lu2022fantastically,
  title={Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity},
  author={Lu, Yao and Bartolo, Max and Moore, Alastair and Riedel, Sebastian and Stenetorp, Pontus},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={8086--8098},
  year={2022}
}

@article{zhuo2023exploring,
  title={Exploring ai ethics of chatgpt: A diagnostic analysis},
  author={Zhuo, Terry Yue and Huang, Yujin and Chen, Chunyang and Xing, Zhenchang},
  journal={arXiv preprint arXiv:2301.12867},
  year={2023}
}